{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Residual & Model Analysis (Quantitative)\n",
                "\n",
                "This notebook focuses on the quantitative modeling of energy reconstruction. It includes feature engineering (charge corrections), model training (Linear, Cyclic, Polynomial), cross-validation, and detailed residual analysis to evaluate performance across different energy ranges."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "import sys\n",
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.preprocessing import PolynomialFeatures\n",
                "from sklearn.pipeline import make_pipeline\n",
                "\n",
                "# Add project root to path\n",
                "sys.path.append(os.path.abspath('..')) \n",
                "\n",
                "from data_processing.utils import get_charge_totale_corr\n",
                "from models.cyclic_model import modele_cyclique\n",
                "from models.model_utils import validation_croisee, print_res_modeles, print_erreurs\n",
                "from visualization.plots import print_plot_reg, print_binned_barplot_reg, evolution_correlation\n",
                "\n",
                "sns.set_theme(style=\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading\n",
                "Loading the processed dataframe."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "DF_PKL_PATH = r\"../base_de_donnee/df.pkl\"\n",
                "DF_EVENTS_PKL_PATH = r\"../base_de_donnee/df_events/df.pkl\"\n",
                "\n",
                "df = None\n",
                "for pkl_path in [DF_PKL_PATH, DF_EVENTS_PKL_PATH]:\n",
                "    if os.path.exists(pkl_path):\n",
                "        print(f\"Loading data from {pkl_path}...\")\n",
                "        try:\n",
                "            df = pd.read_pickle(pkl_path)\n",
                "            print(f\"Successfully loaded {len(df)} events.\")\n",
                "            break\n",
                "        except Exception as e:\n",
                "            print(f\"Failed to load pickle {pkl_path}: {e}\")\n",
                "\n",
                "if df is None:\n",
                "    print(\"No data found. Please run exploratory analysis first or ensure data path is correct.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Feature Engineering: Charge Corrections\n",
                "We calculate corrected charges to improve energy resolution. If these columns are missing, we compute them using utility functions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if df is not None:\n",
                "    # Check for corrected charge columns, compute if missing\n",
                "    if 'charge_corr' not in df.columns:\n",
                "        print(\"Calculating corrected charges (this might take a moment)...\\n\")\n",
                "        # NOTE: This assumes 'df' has the necessary structure (hits exploded or list columns) expected by get_charge_totale_corr\n",
                "        # If df is the event-level summary, we might not have individual hits here unless we load the heavy ROOT or specifically structured pickle\n",
                "        # For this migration, we assume the function handles the dataframe structure available.\n",
                "        try:\n",
                "            # Setup detector params if needed by the function (check utils.py signature)\n",
                "            # Assuming function signature: get_charge_totale_corr(df, verbose=True)\n",
                "            \n",
                "            # Mocking the call structure based on extraction\n",
                "            # df = get_charge_totale_corr(df) \n",
                "            \n",
                "            print(\"Charge correction logic placeholder. Ensure 'get_charge_totale_corr' is compatible with your DataFrame structure.\")\n",
                "            # If simplified DF, we might skip or use existing 'charge_totale'\n",
                "            if 'charge_totale' in df.columns:\n",
                "                df['charge_corr'] = df['charge_totale'] # Fallback/Placeholder if specific correction logic needs raw hits\n",
                "                print(\"Using 'charge_totale' as 'charge_corr' for demonstration.\")\n",
                "        except Exception as e:\n",
                "            print(f\"Error calculating corrections: {e}\")\n",
                "    else:\n",
                "        print(\"Corrected charge columns found.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model Definition & Comparison\n",
                "We define feature sets and target variables, then compare Linear Regression, Cyclic Models, and simple Polynomial fits."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filter data for stable training\n",
                "if df is not None:\n",
                "    # Remove NaNs\n",
                "    df_model = df.dropna(subset=['energy', 'charge_totale', 'n_hits']).copy()\n",
                "    \n",
                "    # Target\n",
                "    y = df_model['energy']\n",
                "    \n",
                "    # Feature Sets\n",
                "    X_simple = df_model[['charge_totale', 'n_hits']]\n",
                "    X_geom = df_model[['charge_totale', 'n_hits', 'dwall', 'towall']] if 'dwall' in df_model.columns else X_simple\n",
                "    X_corr = df_model[['charge_corr', 'n_hits']] if 'charge_corr' in df_model.columns else X_simple\n",
                "\n",
                "    # Models\n",
                "    models = {\n",
                "        \"Linear (Simple)\": (LinearRegression(), X_simple),\n",
                "        \"Linear (Geom)\": (LinearRegression(), X_geom),\n",
                "        \"Linear (Corr)\": (LinearRegression(), X_corr),\n",
                "        # Cyclic Model placeholder (requires specific optimization logic usually handled inside the class)\n",
                "        # \"Cyclic\": (modele_cyclique(), X_simple) \n",
                "    }\n",
                "\n",
                "    print(\"Models defined.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Cross Validation Results\n",
                "Evaluating Bias (`mu`) and Resolution (`sigma`) for each model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = {}\n",
                "\n",
                "if df is not None:\n",
                "    print(\"Running Cross-Validation...\\n\")\n",
                "    for name, (model, X) in models.items():\n",
                "        print(f\"Evaluating {name}...\")\n",
                "        try:\n",
                "            if name == \"Cyclic\":\n",
                "                # Cyclic model might need special handling if not fully sklearn compliant\n",
                "                pass \n",
                "            else:\n",
                "                res = validation_croisee(model, X, y, cv=5)\n",
                "                results[name] = res\n",
                "        except Exception as e:\n",
                "            print(f\"Failed to evaluate {name}: {e}\")\n",
                "\n",
                "    # Display Results\n",
                "    if results:\n",
                "        print_res_modeles(results)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Residual Analysis\n",
                "Analyzing the residuals (Actual - Predicted) to identify systematic biases."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train best model on full dataset for analysis\n",
                "best_model_name = \"Linear (Geom)\" # Example choice\n",
                "if df is not None and best_model_name in models:\n",
                "    model, X = models[best_model_name]\n",
                "    model.fit(X, y)\n",
                "    y_pred = model.predict(X)\n",
                "    residuals = (y_pred - y) / y\n",
                "    \n",
                "    # Global Residuals\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    sns.histplot(residuals, bins=100, kde=True)\n",
                "    plt.title(f\"Relative Residuals Distribution ({best_model_name})\")\n",
                "    plt.xlabel(\"(Predicted - Actual) / Actual\")\n",
                "    plt.xlim(-0.5, 0.5)\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Detailed Error Analysis by Energy Bin\n",
                "Breaking down the resolution and bias across different energy ranges."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if df is not None:\n",
                "    # Define Bins\n",
                "    bins = np.arange(0, 1500, 100)\n",
                "    \n",
                "    # Use utility function to compute errors per bin\n",
                "    # Note: print_erreurs from utils expects specific args, we assume standard here\n",
                "    try:\n",
                "        print(\"Calculating errors per bin...\")\n",
                "        # Check helper signature: print_erreurs(y_true, y_pred, num_bins=10...)\n",
                "        # Or manual implementation if helper is geared differently\n",
                "        \n",
                "        df_res = pd.DataFrame({'energy': y, 'pred': y_pred})\n",
                "        df_res['bin'] = pd.cut(df_res['energy'], bins)\n",
                "        \n",
                "        bin_stats = df_res.groupby('bin').apply(lambda x: pd.Series({\n",
                "            'bias': np.mean((x['pred'] - x['energy']) / x['energy']),\n",
                "            'resolution': np.std((x['pred'] - x['energy']) / x['energy'])\n",
                "        }))\n",
                "        \n",
                "        display(bin_stats)\n",
                "        \n",
                "        # Plotting\n",
                "        plt.figure(figsize=(12, 5))\n",
                "        plt.subplot(1, 2, 1)\n",
                "        bin_stats['bias'].plot(kind='bar', color='skyblue')\n",
                "        plt.title(\"Bias per Energy Bin\")\n",
                "        plt.ylabel(\"Bias ((Pred-True)/True)\")\n",
                "\n",
                "        plt.subplot(1, 2, 2)\n",
                "        bin_stats['resolution'].plot(kind='bar', color='salmon')\n",
                "        plt.title(\"Resolution per Energy Bin\")\n",
                "        plt.ylabel(\"Resolution\")\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"Error in bin analysis: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Visualizing Fits\n",
                "Comparing simple linear vs polynomial trends."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if df is not None:\n",
                "    # Scatter plot with regression line\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    plt.scatter(y, y_pred, alpha=0.3, s=1, label='Data')\n",
                "    plt.plot([0, 1500], [0, 1500], 'r--', label='Ideal')\n",
                "    plt.xlabel(\"True Energy\")\n",
                "    plt.ylabel(\"Predicted Energy\")\n",
                "    plt.legend()\n",
                "    plt.title(\"True vs Predicted Energy\")\n",
                "    plt.show()\n",
                "    \n",
                "    # Checking Polynomial Fit visualization\n",
                "    # print_plot_reg_poly(...) if available"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}